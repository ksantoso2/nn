# Balancing Accuracy and Efficiency: CNNs and ViTs for Fashion MNIST Classification

In this project, we aimed to experiment with convolutional neural networks and vision transformers for an image classification task for clothing images. To approach this we began by implementing famous CNN and ViT architectures, then created custom models for our specific task with the aim of improving accuracy and lower computational costs. Ultimately, we found that for our particular data, the Fashion MNIST dataset, the CNNs were both more efficient and more accurate than the vision transformers. We also were able to create a customized CNN architecture that had the highest accuracy and quickest training time between all of the models. We hope these results will contribute to more sustainable and environmentally friendly machine learning practices.

### Sources
[Fashion MNIST dataset](https://www.kaggle.com/datasets/zalando-research/fashionmnist) 
[Pytorch CNN Tutorial](https://github.com/flatplanet/Pytorch-Tutorial-Youtube)
[LeNet 5 architecture](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf)

